{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-14T12:07:45.090359Z","iopub.status.busy":"2024-10-14T12:07:45.089595Z","iopub.status.idle":"2024-10-14T12:09:30.186709Z","shell.execute_reply":"2024-10-14T12:09:30.185541Z","shell.execute_reply.started":"2024-10-14T12:07:45.090316Z"},"trusted":true},"outputs":[],"source":["!pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n","!pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n","!pip install -q -U transformers\n","!pip install -q -U accelerate\n","!pip install -q -U datasets\n","!pip install -q -U trl\n","!pip install -q -U peft"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:57:54.994519Z","iopub.status.busy":"2024-10-14T13:57:54.994119Z","iopub.status.idle":"2024-10-14T13:57:54.999867Z","shell.execute_reply":"2024-10-14T13:57:54.998867Z","shell.execute_reply.started":"2024-10-14T13:57:54.994483Z"},"trusted":true},"outputs":[],"source":["import os\n","import warnings\n","import transformers\n","import torch\n","from datasets import load_dataset\n","from trl import SFTTrainer\n","from peft import LoraConfig, get_peft_model\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from transformers import BitsAndBytesConfig, TrainingArguments\n","import bitsandbytes as bnb"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T12:10:10.563406Z","iopub.status.busy":"2024-10-14T12:10:10.562230Z","iopub.status.idle":"2024-10-14T12:10:10.567375Z","shell.execute_reply":"2024-10-14T12:10:10.566488Z","shell.execute_reply.started":"2024-10-14T12:10:10.563364Z"},"trusted":true},"outputs":[],"source":["warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T12:10:14.514623Z","iopub.status.busy":"2024-10-14T12:10:14.513647Z","iopub.status.idle":"2024-10-14T12:10:14.616488Z","shell.execute_reply":"2024-10-14T12:10:14.615515Z","shell.execute_reply.started":"2024-10-14T12:10:14.514572Z"},"trusted":true},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","secret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n","HF_TOKEN = secret_value_0"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:57:37.872329Z","iopub.status.busy":"2024-10-14T13:57:37.871950Z","iopub.status.idle":"2024-10-14T13:57:44.428672Z","shell.execute_reply":"2024-10-14T13:57:44.427613Z","shell.execute_reply.started":"2024-10-14T13:57:37.872295Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"571a3fb992cb4958a76a2a62589666ed","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name = \"google/gemma-2-2b-it\"\n","\n","compute_dtype = getattr(torch, \"float16\")\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=False,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=compute_dtype,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=\"auto\",\n","    quantization_config=bnb_config,\n","    token=HF_TOKEN\n",")\n","\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","\n","max_seq_length = 1024\n","tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length, token=HF_TOKEN)"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:55:30.224771Z","iopub.status.busy":"2024-10-14T13:55:30.223991Z","iopub.status.idle":"2024-10-14T13:55:31.190254Z","shell.execute_reply":"2024-10-14T13:55:31.189035Z","shell.execute_reply.started":"2024-10-14T13:55:30.224725Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"jgyasu/medqa\", split=\"train\")"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:55:32.799286Z","iopub.status.busy":"2024-10-14T13:55:32.798403Z","iopub.status.idle":"2024-10-14T13:55:32.807675Z","shell.execute_reply":"2024-10-14T13:55:32.806854Z","shell.execute_reply.started":"2024-10-14T13:55:32.799244Z"},"trusted":true},"outputs":[],"source":["subset = dataset.select(range(2000))"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:40:22.011516Z","iopub.status.busy":"2024-10-14T13:40:22.010822Z","iopub.status.idle":"2024-10-14T13:40:22.017553Z","shell.execute_reply":"2024-10-14T13:40:22.016593Z","shell.execute_reply.started":"2024-10-14T13:40:22.011452Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input', 'output'],\n","    num_rows: 2000\n","})"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["subset"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:55:37.558263Z","iopub.status.busy":"2024-10-14T13:55:37.557581Z","iopub.status.idle":"2024-10-14T13:55:37.564080Z","shell.execute_reply":"2024-10-14T13:55:37.562920Z","shell.execute_reply.started":"2024-10-14T13:55:37.558224Z"},"trusted":true},"outputs":[],"source":["def generate_prompt(data_point):\n","\n","    instruction = (\n","    \"You are an expert medical assistant with knowledge in various fields of medicine, including diagnosis, \"\n","    \"treatment, and healthcare recommendations. Please respond to the following question with accurate, \"\n","    \"evidence-based information. Provide sources or explain relevant guidelines when possible, and clearly \"\n","    \"indicate if the information is based on clinical recommendations, medical studies, or general medical knowledge. \"\n","    \"If the question involves medical advice, provide options or note when a professional consultation would be necessary.\"\n","    )\n","\n","    if data_point['input']:\n","        text = (\n","            f\"<start_of_turn>user {instruction} Here is the question: \\n\"\n","            f\"{data_point['input']}<end_of_turn>\\n\"\n","            f\"<start_of_turn>model {data_point['output']}<end_of_turn>\"\n","        )\n","    return text"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:55:43.643231Z","iopub.status.busy":"2024-10-14T13:55:43.642321Z","iopub.status.idle":"2024-10-14T13:55:43.761525Z","shell.execute_reply":"2024-10-14T13:55:43.760729Z","shell.execute_reply.started":"2024-10-14T13:55:43.643189Z"},"trusted":true},"outputs":[],"source":["text_column = [generate_prompt(data_point) for data_point in subset]\n","subset = subset.add_column(\"prompt\", text_column)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:55:46.252846Z","iopub.status.busy":"2024-10-14T13:55:46.251845Z","iopub.status.idle":"2024-10-14T13:55:46.269371Z","shell.execute_reply":"2024-10-14T13:55:46.268485Z","shell.execute_reply.started":"2024-10-14T13:55:46.252786Z"},"trusted":true},"outputs":[],"source":["subset = subset.train_test_split(test_size=0.2)"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:55:47.813727Z","iopub.status.busy":"2024-10-14T13:55:47.812734Z","iopub.status.idle":"2024-10-14T13:55:47.818347Z","shell.execute_reply":"2024-10-14T13:55:47.817250Z","shell.execute_reply.started":"2024-10-14T13:55:47.813682Z"},"trusted":true},"outputs":[],"source":["train_data = subset[\"train\"]\n","test_data = subset[\"test\"]"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:57:59.084760Z","iopub.status.busy":"2024-10-14T13:57:59.083796Z","iopub.status.idle":"2024-10-14T13:57:59.121551Z","shell.execute_reply":"2024-10-14T13:57:59.120603Z","shell.execute_reply.started":"2024-10-14T13:57:59.084697Z"},"trusted":true},"outputs":[],"source":["output_dir = \"MediGemma\"\n","\n","peft_config = LoraConfig(\n","    lora_alpha=16,\n","    lora_dropout=0,\n","    r=64,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",")\n","\n","training_arguments = TrainingArguments(\n","    output_dir=output_dir,\n","    num_train_epochs=1,\n","    gradient_checkpointing=True,\n","    per_device_train_batch_size=1,\n","    gradient_accumulation_steps=8,\n","    optim=\"paged_adamw_32bit\",\n","    save_steps=0,\n","    logging_steps=25,\n","    learning_rate=5e-4,\n","    weight_decay=0.001,\n","    fp16=True,\n","    bf16=False,\n","    max_grad_norm=0.3,\n","    max_steps=-1,\n","    warmup_ratio=0.03,\n","    group_by_length=False,\n","    evaluation_strategy='steps',\n","    eval_steps = 500,\n","    eval_accumulation_steps=1,\n","    lr_scheduler_type=\"cosine\",\n","    report_to=\"none\",\n",")"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:40:36.044848Z","iopub.status.busy":"2024-10-14T13:40:36.044142Z","iopub.status.idle":"2024-10-14T13:40:39.327217Z","shell.execute_reply":"2024-10-14T13:40:39.326378Z","shell.execute_reply.started":"2024-10-14T13:40:36.044807Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ece101fb12e34c1f94df8e7d7a4ba25e","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16dfffdc870e4ab489663a0a78416ff5","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/400 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=train_data,\n","    eval_dataset=test_data,\n","    peft_config=peft_config,\n","    dataset_text_field=\"prompt\",\n","    tokenizer=tokenizer,\n","    max_seq_length=max_seq_length,\n","    args=training_arguments,\n","    packing=False,\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T12:22:57.535364Z","iopub.status.busy":"2024-10-14T12:22:57.534578Z","iopub.status.idle":"2024-10-14T12:56:46.427459Z","shell.execute_reply":"2024-10-14T12:56:46.426340Z","shell.execute_reply.started":"2024-10-14T12:22:57.535319Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 33:36, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=200, training_loss=1.0529220771789551, metrics={'train_runtime': 2027.3311, 'train_samples_per_second': 0.789, 'train_steps_per_second': 0.099, 'total_flos': 6469581304447488.0, 'train_loss': 1.0529220771789551, 'epoch': 1.0})"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T12:57:28.695801Z","iopub.status.busy":"2024-10-14T12:57:28.695366Z","iopub.status.idle":"2024-10-14T12:57:30.599924Z","shell.execute_reply":"2024-10-14T12:57:30.598967Z","shell.execute_reply.started":"2024-10-14T12:57:28.695762Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('MediGemma/tokenizer_config.json',\n"," 'MediGemma/special_tokens_map.json',\n"," 'MediGemma/tokenizer.model',\n"," 'MediGemma/added_tokens.json',\n"," 'MediGemma/tokenizer.json')"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["trainer.save_model()\n","tokenizer.save_pretrained(output_dir)"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:52:35.676648Z","iopub.status.busy":"2024-10-14T13:52:35.676065Z","iopub.status.idle":"2024-10-14T13:52:40.072920Z","shell.execute_reply":"2024-10-14T13:52:40.072039Z","shell.execute_reply.started":"2024-10-14T13:52:35.676608Z"},"trusted":true},"outputs":[],"source":["import gc\n","\n","del [model, tokenizer, peft_config, trainer, train_data, bnb_config, training_arguments]\n","del [TrainingArguments, SFTTrainer, LoraConfig, BitsAndBytesConfig]\n","\n","for _ in range(10):\n","    torch.cuda.empty_cache()\n","    gc.collect()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T12:57:47.645967Z","iopub.status.busy":"2024-10-14T12:57:47.645196Z","iopub.status.idle":"2024-10-14T12:58:29.572265Z","shell.execute_reply":"2024-10-14T12:58:29.571184Z","shell.execute_reply.started":"2024-10-14T12:57:47.645927Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c15f8b6c9e4741918f73633cedb96f5a","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["('./MediGemma/tokenizer_config.json',\n"," './MediGemma/special_tokens_map.json',\n"," './MediGemma/tokenizer.model',\n"," './MediGemma/added_tokens.json',\n"," './MediGemma/tokenizer.json')"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["from peft import AutoPeftModelForCausalLM\n","\n","finetuned_model = output_dir\n","compute_dtype = getattr(torch, \"float16\")\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","model = AutoPeftModelForCausalLM.from_pretrained(\n","     finetuned_model,\n","     torch_dtype=compute_dtype,\n","     return_dict=False,\n","     low_cpu_mem_usage=True,\n","     device_map=\"auto\",\n",")\n","\n","merged_model = model.merge_and_unload()\n","merged_model.save_pretrained(\"./MediGemma\",\n","                             safe_serialization=True, \n","                             max_shard_size=\"2GB\")\n","tokenizer.save_pretrained(\"./MediGemma\")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T12:58:35.226730Z","iopub.status.busy":"2024-10-14T12:58:35.225751Z","iopub.status.idle":"2024-10-14T12:58:38.551352Z","shell.execute_reply":"2024-10-14T12:58:38.550562Z","shell.execute_reply.started":"2024-10-14T12:58:35.226676Z"},"trusted":true},"outputs":[],"source":["import gc\n","\n","del [model, tokenizer, merged_model, AutoPeftModelForCausalLM]\n","\n","for _ in range(10):\n","    torch.cuda.empty_cache()\n","    gc.collect()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T12:58:56.542539Z","iopub.status.busy":"2024-10-14T12:58:56.541630Z","iopub.status.idle":"2024-10-14T12:58:59.588865Z","shell.execute_reply":"2024-10-14T12:58:59.587822Z","shell.execute_reply.started":"2024-10-14T12:58:56.542481Z"},"trusted":true},"outputs":[],"source":["for _ in range(10):\n","    torch.cuda.empty_cache()\n","    gc.collect()"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:54:27.893895Z","iopub.status.busy":"2024-10-14T13:54:27.893052Z","iopub.status.idle":"2024-10-14T13:54:49.642637Z","shell.execute_reply":"2024-10-14T13:54:49.641793Z","shell.execute_reply.started":"2024-10-14T13:54:27.893859Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f37e08f6fb74f6583f3b1bd0c081d5a","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import (AutoModelForCausalLM, \n","                          AutoTokenizer, \n","                          BitsAndBytesConfig)\n","\n","model_name = \"./MediGemma\"\n","\n","compute_dtype = getattr(torch, \"float16\")\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=False,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=compute_dtype,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=\"auto\",\n","    quantization_config=bnb_config, \n",")\n","\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","\n","max_seq_length = 1024\n","tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:19:53.535653Z","iopub.status.busy":"2024-10-14T13:19:53.534947Z","iopub.status.idle":"2024-10-14T13:20:25.950370Z","shell.execute_reply":"2024-10-14T13:20:25.949417Z","shell.execute_reply.started":"2024-10-14T13:19:53.535603Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    HBV can cause disease and spread when a person has not been immunized or has had no previous hepatitis B infection.\n","    \n","    Hepatitis B has the potential to progress, even in a person who has not had cirrhosis, resulting in death if untreated.\n","    \n","    People with hepatitis B can spread the disease to:\n","    \n","    - their partners\n","    - their unborn child\n","    - their child, if given breast milk\n","    - other people, through blood transfusions, needles, or medical equipment and supplies, if infection develops\n","    \n","    Hepatitis B can become a chronic (long lasting) and dangerous form of disease, called chronic hepatitis B. This occurs when the chronic inflammation or inflammation in the liver due to the virus is severe or lasts for years. People with chronic hepatitis might eventually develop cirrhosis.\n","    \n","    A person with chronic hepatitis B will still remain infected with both hepatitis B surface antigen (HBsAg) and hepatitis B core antigen (HBcAg). It is possible they will also test positive for hepatitis B e antigen (HBeAg). This positive status means the body is continuously producing HBV, causing continued blood, stool, or breast milk contamination by virus, which further increases the risk of infection in others.\n"]}],"source":["def get_completion(query: str, model, tokenizer) -> str:\n","    device = \"cuda:0\"\n","    prompt_template = \"\"\"\n","    <start_of_turn>user You are an expert medical assistant with knowledge in various fields of medicine, including diagnosis, \n","    treatment, and healthcare recommendations. Please respond to the following question with accurate, \n","    evidence-based information. Provide sources or explain relevant guidelines when possible, and clearly \n","    indicate if the information is based on clinical recommendations, medical studies, or general medical knowledge.\n","    If the question involves medical advice, provide options or note when a professional consultation would be necessary.\n","    Here is the question:\n","    {query}\n","    <end_of_turn>\\\\n<start_of_turn>model\n","    \"\"\"\n","    \n","    prompt = prompt_template.format(query=query)\n","    encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n","    model_inputs = encodeds.to(device)\n","    \n","    generated_ids = model.generate(\n","        **model_inputs,\n","        max_new_tokens=1000,\n","        do_sample=True,\n","        pad_token_id=tokenizer.eos_token_id\n","    )\n","    \n","    decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","    model_response_start = \"<start_of_turn>model\"\n","    if model_response_start in decoded:\n","\n","        response = decoded.split(model_response_start)[-1].strip()\n","        return response\n","    else:\n","        return decoded  \n","\n","result = get_completion(query=\"Is Hepatitis B a dangerous disease?\", model=model, tokenizer=tokenizer)\n","result_list = result.split(\"model\")\n","print(result_list[1])\n"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T13:59:56.894091Z","iopub.status.busy":"2024-10-14T13:59:56.893378Z","iopub.status.idle":"2024-10-14T14:01:05.721166Z","shell.execute_reply":"2024-10-14T14:01:05.720197Z","shell.execute_reply.started":"2024-10-14T13:59:56.894051Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc3097fc95a742a0a6bd4e7f5a0a9b28","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/2.32G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/jgyasu/MediGemma/commit/5ec9e8414af94477045330a42046714e1c7ff256', commit_message='Upload Gemma2ForCausalLM', commit_description='', oid='5ec9e8414af94477045330a42046714e1c7ff256', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jgyasu/MediGemma', endpoint='https://huggingface.co', repo_type='model', repo_id='jgyasu/MediGemma'), pr_revision=None, pr_num=None)"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub(\"MediGemma\")"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T14:01:14.199953Z","iopub.status.busy":"2024-10-14T14:01:14.199529Z","iopub.status.idle":"2024-10-14T14:01:17.966241Z","shell.execute_reply":"2024-10-14T14:01:17.965304Z","shell.execute_reply.started":"2024-10-14T14:01:14.199914Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d6e43b8b76143b88846dca447ec31fc","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5dc90178ac5a465685a4838463912417","version_major":2,"version_minor":0},"text/plain":["Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e99781caa95945dd82ec051c10d95919","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77f789cf8d9342c68aa92252569c8d90","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/jgyasu/MediGemma/commit/c78b303d18dd898a7140a876f70a3e34b0979abe', commit_message='Upload tokenizer', commit_description='', oid='c78b303d18dd898a7140a876f70a3e34b0979abe', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jgyasu/MediGemma', endpoint='https://huggingface.co', repo_type='model', repo_id='jgyasu/MediGemma'), pr_revision=None, pr_num=None)"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.push_to_hub(\"MediGemma\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
